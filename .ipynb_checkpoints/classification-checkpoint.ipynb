{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入包\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.py\n",
      "first_round_testing_data.csv\n",
      "first_round_training_data.csv\n",
      "test_score: 0.9638888888888889\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "!ls data/\n",
    "\n",
    "df_train = pd.read_csv(\"data\\\\first_round_training_data.csv\")\n",
    "\n",
    "# 去掉多余的特征\n",
    "#df_train = df_train.drop(df_train.columns[[10,11,12,13,14,15,16,17,18,19,]], axis=1, )\n",
    "df_train = df_train.drop(df_train.columns[[0,1,2,3,4,5,6,7,8,9,10,11,12,  19]], axis=1, )\n",
    "\n",
    "# 特征10 换位到最后一列\n",
    "df_test = pd.read_csv(\"data\\\\first_round_testing_data.csv\")\n",
    "tmp = df_test[\"Parameter10\"].copy()\n",
    "df_test.drop(\"Parameter10\",axis=1, inplace=True)\n",
    "df_test[\"Parameter10\"] = tmp\n",
    "\n",
    "# 制作标签\n",
    "def makeLabel(row):\n",
    "    #print(row)\n",
    "    if row[\"Quality_label\"] == \"Fail\":\n",
    "        return 0\n",
    "    elif row[\"Quality_label\"] == \"Pass\":\n",
    "        return 1\n",
    "    elif row[\"Quality_label\"] == \"Good\":\n",
    "        return 2\n",
    "    elif row[\"Quality_label\"] == \"Excellent\":\n",
    "        return 3\n",
    "\n",
    "df_train[\"Quality_label\"] = df_train.apply(makeLabel, axis=1)   \n",
    "df_train.head()\n",
    "\n",
    "\n",
    "\n",
    "# 划分数据集\n",
    "df_target = df_train[\"Quality_label\"]\n",
    "train = df_train.drop([\"Quality_label\"], axis=1)\n",
    "\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(train,df_target,test_size=0.3, random_state=0)\n",
    "### model-4 xgboost\n",
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test,label=y_test)\n",
    "\n",
    "\n",
    "model = xgb.XGBClassifier(max_depth=5, n_estimators=200, learn_rate=0.01)\n",
    "model.fit(X_train, y_train)  \n",
    "test_score = model.score(X_test, y_test)\n",
    "print('test_score: {0}'.format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute3</th>\n",
       "      <th>Attribute4</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>Quality_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168761</td>\n",
       "      <td>1.098755</td>\n",
       "      <td>36.955992</td>\n",
       "      <td>8.454598</td>\n",
       "      <td>11.438066</td>\n",
       "      <td>177.243120</td>\n",
       "      <td>338.729256</td>\n",
       "      <td>2.021704</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.649033</td>\n",
       "      <td>0.066671</td>\n",
       "      <td>225.632949</td>\n",
       "      <td>0.481860</td>\n",
       "      <td>20597.447822</td>\n",
       "      <td>3.723330</td>\n",
       "      <td>15.376190</td>\n",
       "      <td>0.986973</td>\n",
       "      <td>4.634376</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.078213</td>\n",
       "      <td>110.079689</td>\n",
       "      <td>2.208138</td>\n",
       "      <td>0.073525</td>\n",
       "      <td>236.079314</td>\n",
       "      <td>0.064196</td>\n",
       "      <td>0.576302</td>\n",
       "      <td>33.875790</td>\n",
       "      <td>1.813727</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.380281</td>\n",
       "      <td>0.011491</td>\n",
       "      <td>0.654517</td>\n",
       "      <td>0.025872</td>\n",
       "      <td>176.948915</td>\n",
       "      <td>0.029777</td>\n",
       "      <td>0.246726</td>\n",
       "      <td>27.117165</td>\n",
       "      <td>0.081819</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.555672</td>\n",
       "      <td>38.613386</td>\n",
       "      <td>0.260989</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>194.798039</td>\n",
       "      <td>0.055053</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>13.569707</td>\n",
       "      <td>18.138496</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attribute2  Attribute3  Attribute4  Attribute5    Attribute6  Attribute7  \\\n",
       "0    0.168761    1.098755   36.955992    8.454598     11.438066  177.243120   \n",
       "1   11.649033    0.066671  225.632949    0.481860  20597.447822    3.723330   \n",
       "2    0.078213  110.079689    2.208138    0.073525    236.079314    0.064196   \n",
       "3    0.380281    0.011491    0.654517    0.025872    176.948915    0.029777   \n",
       "4    1.555672   38.613386    0.260989    0.009380    194.798039    0.055053   \n",
       "\n",
       "   Attribute8  Attribute9  Attribute10 Quality_label  \n",
       "0  338.729256    2.021704     0.079526          Pass  \n",
       "1   15.376190    0.986973     4.634376          Fail  \n",
       "2    0.576302   33.875790     1.813727          Fail  \n",
       "3    0.246726   27.117165     0.081819          Fail  \n",
       "4    0.014725   13.569707    18.138496          Fail  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_score: 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(res, target):\n",
    "    if len(res) != len(target):\n",
    "        raise Exception(\"数据错误\")\n",
    "    \n",
    "    trueNum = 0\n",
    "    for i in range(len(res)):\n",
    "        if res[i] == y_train.iloc[i]:\n",
    "            trueNum += 1\n",
    "    print(float(trueNum/len(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_score: 0.995\n"
     ]
    }
   ],
   "source": [
    "# 划分数据集\n",
    "df_target = df_train[\"Quality_label\"]\n",
    "train = df_train.drop([\"Quality_label\"], axis=1)\n",
    "\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(train,df_target,test_size=0.3, random_state=0)\n",
    "### model-4 xgboost\n",
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test,label=y_test)\n",
    "\n",
    "\n",
    "model = xgb.XGBClassifier(max_depth=5, n_estimators=200, learn_rate=0.01)\n",
    "model.fit(X_train, y_train)  \n",
    "test_score = model.score(X_test, y_test)\n",
    "print('test_score: {0}'.format(test_score))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#对数据的训练集进行标准化\n",
    "\n",
    "# x = X_train.copy()\n",
    "# ss = StandardScaler()\n",
    "# X= ss.fit_transform(x)\n",
    "\n",
    "\n",
    "## model -1 逻辑回归\n",
    "# clf = LogisticRegression(random_state=2, solver='lbfgs',multi_class='multinomial',max_iter = 1000).fit(X, y_train)\n",
    "# print(clf.score(X,y_train))\n",
    "\n",
    "\n",
    "### model -2  决策树 \n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# treeClf = DecisionTreeClassifier(\n",
    "#                                      max_depth=7\n",
    "#                                    # ,splitter = \"random\"\n",
    "#                                     ,min_samples_split = 40\n",
    "#                                     ,random_state = 6\n",
    "    \n",
    "#                                         )\n",
    "# treeClf = treeClf.fit(X_train, y_train)\n",
    "# res = treeClf.score(X_test,y_test)\n",
    "# print(res)\n",
    "\n",
    "### model-3  随机森林  # 最好成绩 0.44\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rfc = RandomForestClassifier(\n",
    "#                           n_estimators=100  # 默认10，决策树的数量, 越多越好，从100开始。\n",
    "                          \n",
    "#                         , bootstrap=True   # 有放回采样\n",
    "#                         , oob_score=False  # out-of-bag 使用没有抽到的数据做验证\n",
    "#                         , n_jobs=None      #并行计算\n",
    "#                         , verbose=0        # 打印训练日志\n",
    "#                         , warm_start=False  # 热启动\n",
    "                        \n",
    "#                         #与决策树相关的参数\n",
    "#                         , criterion='gini'  # 或 \"entropy\" \n",
    "#                         , random_state=None\n",
    "#                         , class_weight=None\n",
    "#                         , max_depth=None\n",
    "#                         , min_samples_split=2\n",
    "#                         , min_samples_leaf=1\n",
    "#                         , min_weight_fraction_leaf=0.0\n",
    "#                         , max_features='auto' # auto=特征数的开根号，log2=log2(n_features)， None = n_features\n",
    "#                         , max_leaf_nodes=None\n",
    "#                         , min_impurity_decrease=0.0\n",
    "#                         , min_impurity_split=None\n",
    "#                         )\n",
    "\n",
    "# rfc = rfc.fit(X_train, y_train)\n",
    "# score = rfc.score(X_test,y_test)\n",
    "# print(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.DMatrix at 0x1fbca5eff28>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每轮迭代运行结果:[0.49583333 0.4985     0.5005     0.50266667 0.49383333 0.498\n",
      " 0.49816667 0.49883333]\n",
      "参数的最佳取值：{'random_state': 2019}\n",
      "最佳模型得分:0.5026666666666667\n"
     ]
    }
   ],
   "source": [
    "### 调参过程\n",
    "\n",
    "# score_list = []\n",
    "# for c in range(340,380,2):\n",
    "#     model = xgb.XGBClassifier(\n",
    "#           max_depth=5\n",
    "#         , learning_rate=0.1\n",
    "#         , n_estimators=c   # step1: 360\n",
    "#         , verbosity=1\n",
    "#         , silent=None\n",
    "#         , objective='reg:squarederror'\n",
    "#         , booster='gbtree'\n",
    "#         , min_child_weight=1\n",
    "\n",
    "#         , scale_pos_weight=1\n",
    "#         , base_score=0.5\n",
    "#         , random_state=0\n",
    "#         , seed=None\n",
    "#         , missing=None\n",
    "#         , importance_type='gain',\n",
    "        \n",
    "#         )\n",
    "#     model.fit(X_train, y_train)  \n",
    "#     test_score = model.score(X_test, y_test)\n",
    "#     #print('test_score: {0}'.format(test_score))\n",
    "#     score_list.append(test_score)\n",
    "# print(\"best n_estimators: \", range(340,380,2)[score_list.index(max(score_list))])\n",
    "# print(\"best score:\", max(score_list))\n",
    "# plt.figure(figsize=[8,4])\n",
    "# plt.plot(range(340,380,2),score_list)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dtest = xgb.DMatrix(X_test,label=y_test)\n",
    "cv_params = {'random_state': [42,2,3,2019,2000,10,1,6666]}\n",
    "other_params = {    \n",
    "                   # step1: 24\n",
    "                    \"n_estimators\":200\n",
    "    \n",
    "                  # step2: 4, 3\n",
    "                    , \"max_depth\":4\n",
    "                    , \"min_child_weight\" : 3\n",
    "    \n",
    "                  # step3:\n",
    "                    , \"subsample\" : 0.7\n",
    "                    , \"colsample_bytree\" : 1\n",
    "    \n",
    "                \n",
    "                    , \"learning_rate\":0.1\n",
    "                \n",
    "                    , \"verbosity\":1\n",
    "                    , \"silent\":None\n",
    "                    , \"objective\":'binary:logistic'\n",
    "                    , \"booster\": \"gbtree\"\n",
    "                    , \"n_jobs\" : 1\n",
    "                    , \"nthread\" : None\n",
    "                    , \"gamma\" : 0\n",
    "                  \n",
    "                    , \"max_delta_step\" : 0\n",
    "\n",
    "                    , \"colsample_bylevel\" : 1\n",
    "                    , \"colsample_bynode\" : 1\n",
    "                    , \"reg_alpha\" : 0\n",
    "                    , \"reg_lambda\" : 1\n",
    "                    , \"scale_pos_weight\" : 1\n",
    "                    , \"base_score\" : 0.5\n",
    "                  #  , \"random_state\" : 42\n",
    "                    , \"seed\"  : None\n",
    "                    , \"missing\" : None\n",
    "                    , \"importance_type\" :'gain'\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(**other_params)\n",
    "optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='accuracy', cv=5, verbose=1, n_jobs=1)\n",
    "optimized_GBM.fit(train, df_target)\n",
    "\n",
    "evalute_result = optimized_GBM.cv_results_['mean_test_score']\n",
    "print('每轮迭代运行结果:{0}'.format(evalute_result))\n",
    "print('参数的最佳取值：{0}'.format(optimized_GBM.best_params_))\n",
    "print('最佳模型得分:{0}'.format(optimized_GBM.best_score_))\n",
    "\n",
    "# 0.5118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "model = xgb.XGBClassifier(learning_rate=0.1, n_estimators=24, max_depth=4, min_child_weight=3, seed=0,\n",
    "                         subsample=0.7, colsample_bytree=1, gamma=0, reg_alpha=0, reg_lambda=1)\n",
    "model.fit(train, df_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "testRes = model.predict(df_test.iloc[:,1:-1])\n",
    "\n",
    "testpredict = model.predict_proba(df_test.iloc[:,1:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(\n",
    "    testpredict, columns=[\"Excellent ratio\", \"Good ratio\", \"Pass ratio\", \"Fail ratio\"]\n",
    ")\n",
    "y_pred[\"Group\"] = df_test[\"Group\"]\n",
    "\n",
    "group_pred = y_pred.groupby(\"Group\").mean()\n",
    "for c in [\"Excellent ratio\", \"Good ratio\", \"Pass ratio\", \"Fail ratio\"]:\n",
    "    group_pred[c] /= group_pred.sum(axis=1)\n",
    "    \n",
    "\n",
    "group_pred.to_csv('./result1.csv', index=True, header=True)\n",
    "group_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别结果加到原始的测试集\n",
    "df_test = pd.concat([df_test, pd.DataFrame(data=testRes)], axis=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_csv = pd.read_csv(\"submit_example.csv\")\n",
    "submit_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分组计算 概率\n",
    "g = df_test.groupby(\"Group\")\n",
    "group_list = df_test.Group.unique()\n",
    "\n",
    "for i in group_list:\n",
    "    tmp = g.get_group(i)\n",
    "    Excellent = len(tmp[tmp[0]==3])/50.0\n",
    "    Good = len(tmp[tmp[0]==2])/50.0\n",
    "    Pass = len(tmp[tmp[0]==1])/50.0\n",
    "    Fail = len(tmp[tmp[0]==0])/50.0\n",
    "    submit_csv[submit_csv[\"Group\"]==i] = [i, Excellent, Good, Pass, Fail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = g.get_group(1)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submit_csv.to_csv('./result.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
