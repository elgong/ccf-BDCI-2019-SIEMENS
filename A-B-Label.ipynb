{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgbooost\n",
    "\n",
    "A 预测B,\n",
    "B 再去预测类别\n",
    "对B离散化了，找到了B的准确阈值，\n",
    "调参能力太差，搞不定。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 训练集\n",
    "\n",
    "1. 将训练集特征划分为两部分: df_train_A,df_train_B\n",
    "2. 用 df_train_A 去回归 df_train_B\n",
    "3. 再用df_train_B 去预测 df_target\n",
    "4. 别问为什么了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter1</th>\n",
       "      <th>Parameter2</th>\n",
       "      <th>Parameter3</th>\n",
       "      <th>Parameter4</th>\n",
       "      <th>Parameter5</th>\n",
       "      <th>Parameter6</th>\n",
       "      <th>Parameter7</th>\n",
       "      <th>Parameter8</th>\n",
       "      <th>Parameter9</th>\n",
       "      <th>Parameter10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.591013</td>\n",
       "      <td>147.608373</td>\n",
       "      <td>38.186345</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.601749</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.035864</td>\n",
       "      <td>51.130326</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.098039</td>\n",
       "      <td>69.233685</td>\n",
       "      <td>0.080920</td>\n",
       "      <td>0.112265</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.181860</td>\n",
       "      <td>0.047325</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>1.098102</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012085</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>524.327396</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parameter1  Parameter2  Parameter3  Parameter4  Parameter5  Parameter6  \\\n",
       "0    0.001660    0.591013  147.608373   38.186345    0.000421    0.000612   \n",
       "1    1.601749    0.015052    0.035864   51.130326    0.000909    0.002397   \n",
       "2    0.098039   69.233685    0.080920    0.112265    0.000909    0.001972   \n",
       "3   18.181860    0.047325    0.018061    1.098102    0.000909    0.002397   \n",
       "4    0.012085    0.008749    0.005509  524.327396    0.000909    0.002397   \n",
       "\n",
       "    Parameter7  Parameter8  Parameter9  Parameter10  \n",
       "0  2286.523413    0.035407    0.593081     1.010385  \n",
       "1  2286.523413    0.035407    0.593081     1.010385  \n",
       "2  2286.523413    0.035407    0.593081     1.010385  \n",
       "3  2286.523413    0.035407    0.593081     1.010385  \n",
       "4  2286.523413    0.035407    0.593081     1.010385  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data\\\\first_round_training_data.csv\")\n",
    "df_train_A = df_train.drop(df_train.columns[[     10,11,12,13,14,15,16,17,18,19,20]], axis=1, )\n",
    "df_train_B = df_train.drop(df_train.columns[[0,1,2,3,4,5,6,7,8,9,20]], axis=1, )\n",
    "df_target = df_train[\"Quality_label\"].map({\"Excellent\":3,\"Good\":2,\"Pass\":1,\"Fail\":0})\n",
    "\n",
    "df_train_A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 测试集\n",
    "\n",
    "> 特征位置有问题，特征10 换位到最后一列\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 以B的每个参数为回归目标，训练多个网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B的参数为B1~B10, 根据对比实验，可以跳过B1,B2,B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每轮迭代运行结果:[0.6955]\n",
      "参数的最佳取值：{'max_depth': 9, 'n_estimators': 95}\n",
      "最佳模型得分:0.6955\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Parameter1</th>\n",
       "      <th>Parameter2</th>\n",
       "      <th>Parameter3</th>\n",
       "      <th>Parameter4</th>\n",
       "      <th>Parameter5</th>\n",
       "      <th>Parameter6</th>\n",
       "      <th>Parameter7</th>\n",
       "      <th>Parameter8</th>\n",
       "      <th>Parameter9</th>\n",
       "      <th>Parameter10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.658350</td>\n",
       "      <td>-7.364394</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.220034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.718906</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.101221</td>\n",
       "      <td>0.875409</td>\n",
       "      <td>2.008957</td>\n",
       "      <td>1.917920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.718906</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.610970</td>\n",
       "      <td>1.258616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.814935</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.016205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.700768</td>\n",
       "      <td>1.449469</td>\n",
       "      <td>-0.419122</td>\n",
       "      <td>1.210140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.680578</td>\n",
       "      <td>-2.510142</td>\n",
       "      <td>1.616313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.879412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1.727217</td>\n",
       "      <td>1.197968</td>\n",
       "      <td>-0.154805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1.757734</td>\n",
       "      <td>-3.302936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.425427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.543933</td>\n",
       "      <td>0.430342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1.614632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.766268</td>\n",
       "      <td>2.161946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.649023</td>\n",
       "      <td>0.964718</td>\n",
       "      <td>0.551669</td>\n",
       "      <td>1.328081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.741379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.498654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.509369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.548327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.067243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.195371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.509369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.548327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1.913743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.687163</td>\n",
       "      <td>1.011504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.509369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.548327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.788161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.509369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.548327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.219816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.509369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.548327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.509369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.548327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.751785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.509369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.548327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.868828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.509369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.406153</td>\n",
       "      <td>1.501749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.334924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.843656</td>\n",
       "      <td>-0.013289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.658350</td>\n",
       "      <td>0.551669</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1.325441</td>\n",
       "      <td>1.534315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.742408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.718906</td>\n",
       "      <td>-0.937988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1.871456</td>\n",
       "      <td>1.932574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.662359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1.891915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.229842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.509369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.548327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1.351050</td>\n",
       "      <td>-0.357510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.252071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1.710032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540143</td>\n",
       "      <td>0.586431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>0.551669</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1.471901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685988</td>\n",
       "      <td>-1.698142</td>\n",
       "      <td>0.618500</td>\n",
       "      <td>0.586431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>1.406153</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139267</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.658350</td>\n",
       "      <td>-7.364394</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.658350</td>\n",
       "      <td>-7.364394</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.268471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.439047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.237581</td>\n",
       "      <td>0.241062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>0.551669</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>119</td>\n",
       "      <td>0.399648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.967981</td>\n",
       "      <td>1.193864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.799140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.548327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>119</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>1.716560</td>\n",
       "      <td>1.454967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.252071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.718906</td>\n",
       "      <td>0.325298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>119</td>\n",
       "      <td>1.397841</td>\n",
       "      <td>1.366553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.517157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.298225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.056891</td>\n",
       "      <td>-2.372429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.771968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>1.406153</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>119</td>\n",
       "      <td>-0.235212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.504573</td>\n",
       "      <td>-2.372429</td>\n",
       "      <td>-1.649023</td>\n",
       "      <td>0.964718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.168902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>119</td>\n",
       "      <td>1.089098</td>\n",
       "      <td>1.543164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.433527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.795576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.571012</td>\n",
       "      <td>0.030262</td>\n",
       "      <td>0.790512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.893763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.255403</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>119</td>\n",
       "      <td>1.615954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.799140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.937988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>119</td>\n",
       "      <td>-0.127956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540143</td>\n",
       "      <td>-0.969860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>119</td>\n",
       "      <td>1.342661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540143</td>\n",
       "      <td>0.818075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.099666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5982</th>\n",
       "      <td>119</td>\n",
       "      <td>1.376730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.509486</td>\n",
       "      <td>0.688956</td>\n",
       "      <td>0.241062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.780453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755756</td>\n",
       "      <td>1.520730</td>\n",
       "      <td>1.386275</td>\n",
       "      <td>0.103364</td>\n",
       "      <td>-0.013289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>119</td>\n",
       "      <td>1.775600</td>\n",
       "      <td>1.337446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.649023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.718906</td>\n",
       "      <td>1.665511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.375970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>0.551669</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.325105</td>\n",
       "      <td>0.103364</td>\n",
       "      <td>0.818075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5987</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.752807</td>\n",
       "      <td>0.818075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.325298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5988</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.760490</td>\n",
       "      <td>0.237581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>0.551669</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>119</td>\n",
       "      <td>-1.271627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.279258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.348351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>0.551669</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5990</th>\n",
       "      <td>119</td>\n",
       "      <td>2.011600</td>\n",
       "      <td>1.647829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.325298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.088530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.649023</td>\n",
       "      <td>0.964718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.710615</td>\n",
       "      <td>0.237581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>0.551669</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>119</td>\n",
       "      <td>1.211966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.723977</td>\n",
       "      <td>0.711943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002164</td>\n",
       "      <td>1.229892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.328081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>119</td>\n",
       "      <td>1.704948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.799140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.328081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.597886</td>\n",
       "      <td>0.992097</td>\n",
       "      <td>-0.504573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>0.551669</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650728</td>\n",
       "      <td>1.003222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.253614</td>\n",
       "      <td>-0.375970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.039727</td>\n",
       "      <td>0.551669</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.666483</td>\n",
       "      <td>1.682530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.658350</td>\n",
       "      <td>-7.364394</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Group  Parameter1  Parameter2  Parameter3  Parameter4  Parameter5  \\\n",
       "0         0         NaN         NaN         NaN         NaN         NaN   \n",
       "1         0         NaN    1.220034         NaN    1.195710         NaN   \n",
       "2         0    1.101221    0.875409    2.008957    1.917920         NaN   \n",
       "3         0         NaN         NaN    1.610970    1.258616         NaN   \n",
       "4         0    0.814935    0.999622         NaN    1.016205         NaN   \n",
       "5         0    1.700768    1.449469   -0.419122    1.210140         NaN   \n",
       "6         0         NaN   -0.680578   -2.510142    1.616313         NaN   \n",
       "7         0         NaN         NaN         NaN    1.879412         NaN   \n",
       "8         0    1.727217    1.197968   -0.154805         NaN         NaN   \n",
       "9         0    1.757734   -3.302936         NaN    0.425427         NaN   \n",
       "10        0         NaN    1.543933    0.430342         NaN         NaN   \n",
       "11        0    1.614632         NaN   -0.766268    2.161946         NaN   \n",
       "12        0         NaN    1.741379         NaN   -0.498654         NaN   \n",
       "13        0         NaN    1.067243         NaN   -0.195371         NaN   \n",
       "14        0    1.913743         NaN   -1.687163    1.011504         NaN   \n",
       "15        0    0.788161         NaN    0.731647         NaN         NaN   \n",
       "16        0         NaN    0.219816         NaN         NaN         NaN   \n",
       "17        0         NaN         NaN         NaN         NaN         NaN   \n",
       "18        0    0.751785         NaN         NaN         NaN         NaN   \n",
       "19        0         NaN    1.868828         NaN         NaN         NaN   \n",
       "20        0         NaN   -1.334924         NaN         NaN   -0.843656   \n",
       "21        0    1.325441    1.534315         NaN         NaN         NaN   \n",
       "22        0    1.871456    1.932574         NaN    1.662359         NaN   \n",
       "23        0    1.891915         NaN         NaN    1.229842         NaN   \n",
       "24        0    1.351050   -0.357510         NaN         NaN         NaN   \n",
       "25        0    1.710032         NaN         NaN         NaN    0.540143   \n",
       "26        0    1.471901         NaN    0.685988   -1.698142    0.618500   \n",
       "27        0         NaN    0.139267    0.201900         NaN         NaN   \n",
       "28        0         NaN         NaN    0.995928         NaN         NaN   \n",
       "29        0         NaN    1.268471         NaN         NaN         NaN   \n",
       "...     ...         ...         ...         ...         ...         ...   \n",
       "5970    119         NaN    1.439047         NaN         NaN    0.237581   \n",
       "5971    119    0.399648         NaN   -0.967981    1.193864         NaN   \n",
       "5972    119    1.050000    1.716560    1.454967         NaN         NaN   \n",
       "5973    119    1.397841    1.366553         NaN    1.517157         NaN   \n",
       "5974    119         NaN    1.298225         NaN         NaN   -0.056891   \n",
       "5975    119         NaN         NaN         NaN    1.771968         NaN   \n",
       "5976    119   -0.235212         NaN         NaN         NaN   -0.504573   \n",
       "5977    119    1.089098    1.543164         NaN         NaN         NaN   \n",
       "5978    119         NaN    1.571012    0.030262    0.790512         NaN   \n",
       "5979    119    1.615954         NaN         NaN         NaN         NaN   \n",
       "5980    119   -0.127956         NaN         NaN         NaN    0.540143   \n",
       "5981    119    1.342661         NaN    0.470310         NaN    0.540143   \n",
       "5982    119    1.376730         NaN         NaN   -0.509486    0.688956   \n",
       "5983    119         NaN    0.755756    1.520730    1.386275    0.103364   \n",
       "5984    119    1.775600    1.337446         NaN         NaN         NaN   \n",
       "5985    119         NaN         NaN         NaN         NaN         NaN   \n",
       "5986    119         NaN         NaN         NaN    1.325105    0.103364   \n",
       "5987    119         NaN         NaN         NaN         NaN    0.752807   \n",
       "5988    119         NaN         NaN         NaN    1.760490    0.237581   \n",
       "5989    119   -1.271627         NaN   -2.279258         NaN   -1.348351   \n",
       "5990    119    2.011600    1.647829         NaN         NaN         NaN   \n",
       "5991    119         NaN    1.088530         NaN         NaN         NaN   \n",
       "5992    119         NaN         NaN         NaN    1.710615    0.237581   \n",
       "5993    119    1.211966         NaN         NaN         NaN         NaN   \n",
       "5994    119         NaN    1.723977    0.711943         NaN    1.002164   \n",
       "5995    119    1.704948         NaN         NaN         NaN         NaN   \n",
       "5996    119         NaN         NaN    1.597886    0.992097   -0.504573   \n",
       "5997    119         NaN    0.650728    1.003222         NaN         NaN   \n",
       "5998    119         NaN         NaN         NaN         NaN   -0.253614   \n",
       "5999    119         NaN         NaN   -0.666483    1.682530         NaN   \n",
       "\n",
       "      Parameter6  Parameter7  Parameter8  Parameter9  Parameter10  \n",
       "0            NaN         NaN   -0.658350   -7.364394          NaN  \n",
       "1            NaN         NaN         NaN    1.718906          NaN  \n",
       "2            NaN         NaN         NaN    1.718906          NaN  \n",
       "3            NaN         NaN    1.039727         NaN          NaN  \n",
       "4            NaN         NaN    1.039727         NaN          NaN  \n",
       "5            NaN         NaN    1.039727         NaN          NaN  \n",
       "6            NaN         NaN    1.039727         NaN          NaN  \n",
       "7            NaN         NaN    1.039727         NaN          NaN  \n",
       "8            NaN         NaN    1.039727         NaN          NaN  \n",
       "9            NaN         NaN    1.039727         NaN          NaN  \n",
       "10           NaN         NaN    1.039727         NaN          NaN  \n",
       "11           NaN   -1.649023    0.964718    0.551669     1.328081  \n",
       "12           NaN    1.509369         NaN         NaN     1.548327  \n",
       "13           NaN    1.509369         NaN         NaN     1.548327  \n",
       "14           NaN    1.509369         NaN         NaN     1.548327  \n",
       "15           NaN    1.509369         NaN         NaN     1.548327  \n",
       "16           NaN    1.509369         NaN         NaN     1.548327  \n",
       "17           NaN    1.509369         NaN         NaN     1.548327  \n",
       "18           NaN    1.509369         NaN         NaN     1.548327  \n",
       "19           NaN    1.509369         NaN    1.406153     1.501749  \n",
       "20     -0.013289         NaN   -0.658350    0.551669          NaN  \n",
       "21           NaN    1.742408         NaN    1.718906    -0.937988  \n",
       "22           NaN         NaN         NaN         NaN          NaN  \n",
       "23           NaN    1.509369         NaN         NaN     1.548327  \n",
       "24           NaN    1.252071         NaN         NaN          NaN  \n",
       "25      0.586431         NaN    1.039727    0.551669          NaN  \n",
       "26      0.586431         NaN    1.039727    1.406153          NaN  \n",
       "27           NaN         NaN   -0.658350   -7.364394          NaN  \n",
       "28           NaN         NaN   -0.658350   -7.364394          NaN  \n",
       "29           NaN         NaN    1.039727         NaN          NaN  \n",
       "...          ...         ...         ...         ...          ...  \n",
       "5970    0.241062         NaN    1.039727    0.551669          NaN  \n",
       "5971         NaN    1.799140         NaN         NaN     1.548327  \n",
       "5972         NaN    1.252071         NaN    1.718906     0.325298  \n",
       "5973         NaN         NaN    1.039727         NaN          NaN  \n",
       "5974   -2.372429         NaN         NaN         NaN          NaN  \n",
       "5975   -0.013289         NaN    1.039727    1.406153          NaN  \n",
       "5976   -2.372429   -1.649023    0.964718         NaN     1.168902  \n",
       "5977    0.433527         NaN         NaN         NaN     0.795576  \n",
       "5978         NaN    1.893763         NaN    2.255403          NaN  \n",
       "5979         NaN    1.799140         NaN         NaN    -0.937988  \n",
       "5980   -0.969860         NaN    1.039727         NaN          NaN  \n",
       "5981    0.818075         NaN         NaN         NaN    -0.099666  \n",
       "5982    0.241062         NaN    0.780453         NaN          NaN  \n",
       "5983   -0.013289         NaN    1.039727         NaN          NaN  \n",
       "5984         NaN   -1.649023         NaN    1.718906     1.665511  \n",
       "5985   -0.375970         NaN    1.039727    0.551669          NaN  \n",
       "5986    0.818075         NaN         NaN         NaN          NaN  \n",
       "5987    0.818075         NaN         NaN         NaN     0.325298  \n",
       "5988         NaN         NaN    1.039727    0.551669          NaN  \n",
       "5989         NaN         NaN    1.039727    0.551669          NaN  \n",
       "5990         NaN         NaN         NaN         NaN     0.325298  \n",
       "5991         NaN   -1.649023    0.964718         NaN          NaN  \n",
       "5992         NaN         NaN    1.039727    0.551669          NaN  \n",
       "5993         NaN         NaN    1.039727         NaN          NaN  \n",
       "5994    1.229892         NaN         NaN         NaN     1.328081  \n",
       "5995         NaN    1.799140         NaN         NaN     1.328081  \n",
       "5996         NaN         NaN    1.039727    0.551669          NaN  \n",
       "5997         NaN         NaN    1.039727         NaN          NaN  \n",
       "5998   -0.375970         NaN    1.039727    0.551669          NaN  \n",
       "5999         NaN         NaN   -0.658350   -7.364394          NaN  \n",
       "\n",
       "[6000 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每轮迭代运行结果:[0.6955]\n",
      "参数的最佳取值：{'max_depth': 9, 'n_estimators': 95}\n",
      "最佳模型得分:0.6955\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "每轮迭代运行结果:[0.73816667]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "参数的最佳取值：{'max_depth': 5, 'n_estimators': 5}\n",
      "最佳模型得分:0.7381666666666666\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每轮迭代运行结果:[0.88866667]\n",
      "参数的最佳取值：{'min_samples_leaf': 1, 'min_samples_split': 0.11}\n",
      "最佳模型得分:0.8886666666666667\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "每轮迭代运行结果:[0.84466667]\n",
      "参数的最佳取值：{'min_samples_leaf': 1, 'min_samples_split': 0.11}\n",
      "最佳模型得分:0.8446666666666667\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每轮迭代运行结果:[0.54616667]\n",
      "参数的最佳取值：{'min_samples_leaf': 1, 'min_samples_split': 0.11}\n",
      "最佳模型得分:0.5461666666666667\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每轮迭代运行结果:[0.6885]\n",
      "参数的最佳取值：{'min_samples_split': 0.52}\n",
      "最佳模型得分:0.6885\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每轮迭代运行结果:[0.67583333]\n",
      "参数的最佳取值：{'n_estimators': 90}\n",
      "最佳模型得分:0.6758333333333333\n",
      "Index(['B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10'], dtype='object')\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每轮迭代运行结果:[0.96483333]\n",
      "参数的最佳取值：{'n_estimators': 100}\n",
      "最佳模型得分:0.9648333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train = pd.read_csv(\"data\\\\first_round_training_data.csv\")\n",
    "df_train_A = df_train.drop(df_train.columns[[     10,11,12,13,14,15,16,17,18,19,20]], axis=1, )\n",
    "df_train_B = df_train.drop(df_train.columns[[0,1,2,3,4,5,6,7,8,9,10,11,12,20]], axis=1, )\n",
    "df_target = df_train[\"Quality_label\"].map({\"Excellent\":3,\"Good\":2,\"Pass\":1,\"Fail\":0})\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(\"data\\\\first_round_testing_data.csv\")\n",
    "tmp = df_test[\"Parameter10\"].copy()\n",
    "df_test.drop(\"Parameter10\",axis=1, inplace=True)\n",
    "df_test[\"Parameter10\"] = tmp\n",
    "\n",
    "\n",
    "df_train_B[\"Attribute4\"] = np.log10(df_train_B[\"Attribute4\"])\n",
    "df_train_B[\"Attribute5\"] = np.log10(df_train_B[\"Attribute5\"])\n",
    "df_train_B[\"Attribute6\"] = np.log10(df_train_B[\"Attribute6\"])\n",
    "df_train_B[\"Attribute7\"] = np.log10(df_train_B[\"Attribute7\"])\n",
    "df_train_B[\"Attribute8\"] = np.log10(df_train_B[\"Attribute8\"])\n",
    "df_train_B[\"Attribute9\"] = np.log10(df_train_B[\"Attribute9\"])\n",
    "df_train_B[\"Attribute10\"] = np.log10(df_train_B[\"Attribute10\"])\n",
    "\n",
    "\n",
    "\n",
    "df_train_A[\"Parameter1\"] = np.log2(df_train_A[\"Parameter1\"])\n",
    "df_train_A[\"Parameter2\"] = np.log2(df_train_A[\"Parameter2\"])\n",
    "df_train_A[\"Parameter3\"] = np.log2(df_train_A[\"Parameter3\"])\n",
    "df_train_A[\"Parameter4\"] = np.log2(df_train_A[\"Parameter4\"])\n",
    "df_train_A[\"Parameter5\"] = np.log2(df_train_A[\"Parameter5\"])\n",
    "df_train_A[\"Parameter6\"] = np.log2(df_train_A[\"Parameter6\"])\n",
    "df_train_A[\"Parameter7\"] = np.log2(df_train_A[\"Parameter7\"])\n",
    "df_train_A[\"Parameter8\"] = np.log2(df_train_A[\"Parameter8\"])\n",
    "df_train_A[\"Parameter9\"] = np.log2(df_train_A[\"Parameter9\"])\n",
    "df_train_A[\"Parameter10\"] = np.log2(df_train_A[\"Parameter10\"])\n",
    "\n",
    "\n",
    "df_test[\"Parameter1\"] = np.log2(df_test[\"Parameter1\"])\n",
    "df_test[\"Parameter2\"] = np.log2(df_test[\"Parameter2\"])\n",
    "df_test[\"Parameter3\"] = np.log2(df_test[\"Parameter3\"])\n",
    "df_test[\"Parameter4\"] = np.log2(df_test[\"Parameter4\"])\n",
    "df_test[\"Parameter5\"] = np.log2(df_test[\"Parameter5\"])\n",
    "df_test[\"Parameter6\"] = np.log2(df_test[\"Parameter6\"])\n",
    "df_test[\"Parameter7\"] = np.log2(df_test[\"Parameter7\"])\n",
    "df_test[\"Parameter8\"] = np.log2(df_test[\"Parameter8\"])\n",
    "df_test[\"Parameter9\"] = np.log2(df_test[\"Parameter9\"])\n",
    "df_test[\"Parameter10\"] = np.log2(df_test[\"Parameter10\"])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "new_A  = df_train_A.copy()\n",
    "\n",
    "def find(row):\n",
    "    if row < -0.784:\n",
    "        return 1\n",
    "    elif row < 2.01:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "df_train_B[\"Attribute5\"] = df_train_B[\"Attribute5\"].apply(find)\n",
    "\n",
    "def find(row):\n",
    "    if row < 0.47:\n",
    "        return 1\n",
    "    elif row < 1.75:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "df_train_B[\"Attribute4\"] = df_train_B[\"Attribute4\"].apply(find)\n",
    "\n",
    "def find(row):\n",
    "    if row <-2.195:\n",
    "        return 1\n",
    "    elif row < 2:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "df_train_B[\"Attribute6\"] = df_train_B[\"Attribute6\"].apply(find)\n",
    "\n",
    "def find(row):\n",
    "    if row < 1.2:\n",
    "        return 1\n",
    "    elif row < 2.15:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "df_train_B[\"Attribute7\"] = df_train_B[\"Attribute7\"].apply(find)\n",
    "\n",
    "def find(row):\n",
    "    if row < -1.43:\n",
    "        return 1\n",
    "    elif row < 0.2:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "df_train_B[\"Attribute8\"] = df_train_B[\"Attribute8\"].apply(find)\n",
    "\n",
    "\n",
    "def find(row):\n",
    "    if row < 1.31:\n",
    "        return 1\n",
    "    elif row < 2.39:\n",
    "        return 2\n",
    "    elif row < 3.45:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "df_train_B[\"Attribute9\"] = df_train_B[\"Attribute9\"].apply(find)\n",
    "\n",
    "def find(row):\n",
    "    if row < -1.40:\n",
    "        return 1\n",
    "    elif row < 2.28:\n",
    "        return 2\n",
    "    elif row < 4.3:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "df_train_B[\"Attribute10\"] = df_train_B[\"Attribute10\"].apply(find)\n",
    "\n",
    "\n",
    "res = df_test.copy()\n",
    "\n",
    "\n",
    "#  4\n",
    "tmp = df_train_B[\"Attribute4\"].copy()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_params = {\"n_estimators\": [95], \"max_depth\": [9]}\n",
    "#'min_samples_split': [i*0.01+0.1 for i in range(1,10,1)], \"min_samples_leaf\":[1,2]\n",
    "#  \"n_estimators\": [i for i in range(5,15,1)], \"max_depth\": [i for i in range(1,10,1)]\n",
    "other_params = {    \n",
    "                       \"criterion\" : \"gini\"\n",
    "                       , \"n_estimators\": 95\n",
    "                       ,\"max_depth\"  : 9\n",
    "                       , \"min_samples_split\" : 0.11\n",
    "                       , \"min_samples_leaf\" : 1\n",
    "                       , \"min_weight_fraction_leaf\" : 0.0\n",
    "                       , \"max_features\" : \"auto\"\n",
    "                       , \"max_leaf_nodes\" : None\n",
    "                       , \"min_impurity_decrease\" : 0.0\n",
    "                       , \"min_impurity_split\" : None\n",
    "                       , \"bootstrap\" : True\n",
    "                       , \"oob_score\" : False\n",
    "                       , \"random_state\":42\n",
    "                       , \"class_weight\" : None#\"balanced\"\n",
    "\n",
    "}\n",
    "rfc = RandomForestClassifier(\n",
    "                        **other_params\n",
    "                      )\n",
    "\n",
    "\n",
    "optimized_GBM = GridSearchCV(estimator=rfc, param_grid=cv_params, scoring='accuracy', cv=5, verbose=1, n_jobs=4)\n",
    "optimized_GBM.fit(new_A, tmp)\n",
    "\n",
    "evalute_result = optimized_GBM.cv_results_['mean_test_score']\n",
    "print('每轮迭代运行结果:{0}'.format(evalute_result))\n",
    "print('参数的最佳取值：{0}'.format(optimized_GBM.best_params_))\n",
    "print('最佳模型得分:{0}'.format(optimized_GBM.best_score_))\n",
    "\n",
    "clf = optimized_GBM.best_estimator_\n",
    "\n",
    "# pre = clf.predict_proba(df_test.iloc[:,1:11])\n",
    "pre = clf.predict(df_test.iloc[:,1:11])\n",
    "res[\"B4\"] = pre\n",
    "\n",
    "\n",
    "#  5\n",
    "tmp = df_train_B[\"Attribute5\"].copy()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_params = {\"n_estimators\": [5], \"max_depth\": [5]}\n",
    "#'min_samples_split': [i*0.01+0.1 for i in range(1,10,1)], \"min_samples_leaf\":[1,2]\n",
    "#  \"n_estimators\": [i for i in range(5,15,1)], \"max_depth\": [i for i in range(1,10,1)]\n",
    "other_params = {    \n",
    "                       \"criterion\" : \"gini\"\n",
    "                       , \"n_estimators\": 5\n",
    "                       ,\"max_depth\"  : 5\n",
    "                       , \"min_samples_split\" : 0.11\n",
    "                       , \"min_samples_leaf\" : 1\n",
    "                       , \"min_weight_fraction_leaf\" : 0.0\n",
    "                       , \"max_features\" : \"auto\"\n",
    "                       , \"max_leaf_nodes\" : None\n",
    "                       , \"min_impurity_decrease\" : 0.0\n",
    "                       , \"min_impurity_split\" : None\n",
    "                       , \"bootstrap\" : True\n",
    "                       , \"oob_score\" : False\n",
    "                       , \"random_state\":42\n",
    "                       , \"class_weight\" : None#\"balanced\"\n",
    "\n",
    "}\n",
    "rfc = RandomForestClassifier(\n",
    "                        **other_params\n",
    "                      )\n",
    "\n",
    "\n",
    "optimized_GBM = GridSearchCV(estimator=rfc, param_grid=cv_params, scoring='accuracy', cv=5, verbose=1, n_jobs=4)\n",
    "optimized_GBM.fit(new_A, tmp)\n",
    "\n",
    "evalute_result = optimized_GBM.cv_results_['mean_test_score']\n",
    "print('每轮迭代运行结果:{0}'.format(evalute_result))\n",
    "print('参数的最佳取值：{0}'.format(optimized_GBM.best_params_))\n",
    "print('最佳模型得分:{0}'.format(optimized_GBM.best_score_))\n",
    "\n",
    "clf = optimized_GBM.best_estimator_\n",
    "\n",
    "# pre = clf.predict_proba(df_test.iloc[:,1:11])\n",
    "pre = clf.predict(df_test.iloc[:,1:11])\n",
    "res[\"B5\"] = pre\n",
    "\n",
    "\n",
    "\n",
    "#  6\n",
    "tmp = df_train_B[\"Attribute6\"].copy()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_params = {'min_samples_split': [0.11], \"min_samples_leaf\":[1]}\n",
    "#'min_samples_split': [i*0.01+0.1 for i in range(1,10,1)], \"min_samples_leaf\":[1,2]\n",
    "# \"n_estimators\": [i for i in range(5,15,1)], \"max_depth\": [i for i in range(1,10,1)]\n",
    "other_params = {    \n",
    "                       \"criterion\" : \"gini\"\n",
    "                       , \"n_estimators\": 45\n",
    "                       ,\"max_depth\"  : 9\n",
    "                       , \"min_samples_split\" : 0.11\n",
    "                       , \"min_samples_leaf\" : 1\n",
    "                       , \"min_weight_fraction_leaf\" : 0.0\n",
    "                       , \"max_features\" : \"auto\"\n",
    "                       , \"max_leaf_nodes\" : None\n",
    "                       , \"min_impurity_decrease\" : 0.0\n",
    "                       , \"min_impurity_split\" : None\n",
    "                       , \"bootstrap\" : True\n",
    "                       , \"oob_score\" : False\n",
    "                       , \"random_state\":42\n",
    "                       , \"class_weight\" : None#\"balanced\"\n",
    "\n",
    "}\n",
    "rfc = RandomForestClassifier(\n",
    "                        **other_params\n",
    "                      )\n",
    "\n",
    "\n",
    "optimized_GBM = GridSearchCV(estimator=rfc, param_grid=cv_params, scoring='accuracy', cv=5, verbose=1, n_jobs=4)\n",
    "optimized_GBM.fit(new_A, tmp)\n",
    "\n",
    "evalute_result = optimized_GBM.cv_results_['mean_test_score']\n",
    "print('每轮迭代运行结果:{0}'.format(evalute_result))\n",
    "print('参数的最佳取值：{0}'.format(optimized_GBM.best_params_))\n",
    "print('最佳模型得分:{0}'.format(optimized_GBM.best_score_))\n",
    "\n",
    "clf = optimized_GBM.best_estimator_\n",
    "\n",
    "# pre = clf.predict_proba(df_test.iloc[:,1:11])\n",
    "pre = clf.predict(df_test.iloc[:,1:11])\n",
    "res[\"B6\"] = pre\n",
    "\n",
    "\n",
    "##  7\n",
    "tmp = df_train_B[\"Attribute7\"].copy()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_params = {'min_samples_split': [0.11], \"min_samples_leaf\":[1]}\n",
    "#'min_samples_split': [i*0.01+0.1 for i in range(1,10,1)], \"min_samples_leaf\":[1,2]\n",
    "# \"n_estimators\": [i for i in range(5,15,1)], \"max_depth\": [i for i in range(1,10,1)]\n",
    "other_params = {    \n",
    "                       \"criterion\" : \"gini\"\n",
    "                       , \"n_estimators\": 5\n",
    "                       ,\"max_depth\"  : 1\n",
    "                       , \"min_samples_split\" : 0.11\n",
    "                       , \"min_samples_leaf\" : 1\n",
    "                       , \"min_weight_fraction_leaf\" : 0.0\n",
    "                       , \"max_features\" : \"auto\"\n",
    "                       , \"max_leaf_nodes\" : None\n",
    "                       , \"min_impurity_decrease\" : 0.0\n",
    "                       , \"min_impurity_split\" : None\n",
    "                       , \"bootstrap\" : True\n",
    "                       , \"oob_score\" : False\n",
    "                       , \"random_state\":42\n",
    "                       , \"class_weight\" : None#\"balanced\"\n",
    "\n",
    "}\n",
    "rfc = RandomForestClassifier(\n",
    "                        **other_params\n",
    "                      )\n",
    "\n",
    "\n",
    "optimized_GBM = GridSearchCV(estimator=rfc, param_grid=cv_params, scoring='accuracy', cv=5, verbose=1, n_jobs=4)\n",
    "optimized_GBM.fit(new_A, tmp)\n",
    "\n",
    "evalute_result = optimized_GBM.cv_results_['mean_test_score']\n",
    "print('每轮迭代运行结果:{0}'.format(evalute_result))\n",
    "print('参数的最佳取值：{0}'.format(optimized_GBM.best_params_))\n",
    "print('最佳模型得分:{0}'.format(optimized_GBM.best_score_))\n",
    "\n",
    "clf = optimized_GBM.best_estimator_\n",
    "\n",
    "# pre = clf.predict_proba(df_test.iloc[:,1:11])\n",
    "pre = clf.predict(df_test.iloc[:,1:11])\n",
    "res[\"B7\"] = pre\n",
    "\n",
    "\n",
    "\n",
    "##  8\n",
    "tmp = df_train_B[\"Attribute8\"].copy()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_params = {'min_samples_split': [0.11], \"min_samples_leaf\":[1]}\n",
    "other_params = {    \n",
    "                       \"criterion\" : \"gini\"\n",
    "                       , \"n_estimators\": 133\n",
    "                       ,\"max_depth\"  : 6\n",
    "                       , \"min_samples_split\" : 0.11\n",
    "                       , \"min_samples_leaf\" : 2\n",
    "                       , \"min_weight_fraction_leaf\" : 0.0\n",
    "                       , \"max_features\" : \"auto\"\n",
    "                       , \"max_leaf_nodes\" : None\n",
    "                       , \"min_impurity_decrease\" : 0.0\n",
    "                       , \"min_impurity_split\" : None\n",
    "                       , \"bootstrap\" : True\n",
    "                       , \"oob_score\" : False\n",
    "                       , \"random_state\":42\n",
    "                       , \"class_weight\" : None#\"balanced\"\n",
    "\n",
    "}\n",
    "rfc = RandomForestClassifier(\n",
    "                        **other_params\n",
    "                      )\n",
    "\n",
    "\n",
    "optimized_GBM = GridSearchCV(estimator=rfc, param_grid=cv_params, scoring='accuracy', cv=5, verbose=1, n_jobs=4)\n",
    "optimized_GBM.fit(new_A, tmp)\n",
    "\n",
    "evalute_result = optimized_GBM.cv_results_['mean_test_score']\n",
    "print('每轮迭代运行结果:{0}'.format(evalute_result))\n",
    "print('参数的最佳取值：{0}'.format(optimized_GBM.best_params_))\n",
    "print('最佳模型得分:{0}'.format(optimized_GBM.best_score_))\n",
    "\n",
    "clf = optimized_GBM.best_estimator_\n",
    "\n",
    "# pre = clf.predict_proba(df_test.iloc[:,1:11])\n",
    "pre = clf.predict(df_test.iloc[:,1:11])\n",
    "res[\"B8\"] = pre\n",
    "\n",
    "\n",
    "##  9\n",
    "tmp = df_train_B[\"Attribute9\"].copy()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_params = {'min_samples_split': [0.52]}\n",
    "other_params = {    \n",
    "                       \"criterion\" : \"gini\"\n",
    "                       , \"n_estimators\": 97\n",
    "                       ,\"max_depth\"  : 9\n",
    "                       , \"min_samples_split\" : 0.52\n",
    "                       , \"min_samples_leaf\" : 1\n",
    "                       , \"min_weight_fraction_leaf\" : 0.0\n",
    "                       , \"max_features\" : \"auto\"\n",
    "                       , \"max_leaf_nodes\" : None\n",
    "                       , \"min_impurity_decrease\" : 0.0\n",
    "                       , \"min_impurity_split\" : None\n",
    "                       , \"bootstrap\" : True\n",
    "                       , \"oob_score\" : False\n",
    "                       , \"random_state\":42\n",
    "                       , \"class_weight\" : \"balanced\"\n",
    "\n",
    "}\n",
    "rfc = RandomForestClassifier(\n",
    "                        **other_params\n",
    "                      )\n",
    "\n",
    "\n",
    "optimized_GBM = GridSearchCV(estimator=rfc, param_grid=cv_params, scoring='accuracy', cv=5, verbose=1, n_jobs=4)\n",
    "optimized_GBM.fit(new_A, tmp)\n",
    "\n",
    "evalute_result = optimized_GBM.cv_results_['mean_test_score']\n",
    "print('每轮迭代运行结果:{0}'.format(evalute_result))\n",
    "print('参数的最佳取值：{0}'.format(optimized_GBM.best_params_))\n",
    "print('最佳模型得分:{0}'.format(optimized_GBM.best_score_))\n",
    "\n",
    "clf = optimized_GBM.best_estimator_\n",
    "\n",
    "# pre = clf.predict_proba(df_test.iloc[:,1:11])\n",
    "pre = clf.predict(df_test.iloc[:,1:11])\n",
    "res[\"B9\"] = pre\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  10\n",
    "tmp = df_train_B[\"Attribute10\"].copy()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_params = {'n_estimators': [90] }\n",
    "other_params = {    \n",
    "                       \"criterion\" : \"gini\"\n",
    "                       , \"n_estimators\":90\n",
    "                       ,\"max_depth\"  : 9\n",
    "                       , \"min_samples_split\" : 2\n",
    "                       , \"min_samples_leaf\" : 1\n",
    "                       , \"min_weight_fraction_leaf\" : 0.0\n",
    "                       , \"max_features\" : \"auto\"\n",
    "                       , \"max_leaf_nodes\" : None\n",
    "                       , \"min_impurity_decrease\" : 0.0\n",
    "                       , \"min_impurity_split\" : None\n",
    "                       , \"bootstrap\" : True\n",
    "                       , \"oob_score\" : False\n",
    "                       , \"random_state\":42\n",
    "                       , \"class_weight\" : \"balanced\"\n",
    "\n",
    "}\n",
    "rfc = RandomForestClassifier(\n",
    "                        **other_params\n",
    "                      )\n",
    "\n",
    "\n",
    "optimized_GBM = GridSearchCV(estimator=rfc, param_grid=cv_params, scoring='accuracy', cv=5, verbose=1, n_jobs=4)\n",
    "optimized_GBM.fit(new_A, tmp)\n",
    "\n",
    "evalute_result = optimized_GBM.cv_results_['mean_test_score']\n",
    "print('每轮迭代运行结果:{0}'.format(evalute_result))\n",
    "print('参数的最佳取值：{0}'.format(optimized_GBM.best_params_))\n",
    "print('最佳模型得分:{0}'.format(optimized_GBM.best_score_))\n",
    "\n",
    "clf = optimized_GBM.best_estimator_\n",
    "\n",
    "# pre = clf.predict_proba(df_test.iloc[:,1:11])\n",
    "pre = clf.predict(df_test.iloc[:,1:11])\n",
    "res[\"B10\"] = pre\n",
    "\n",
    "res = res.drop(res.columns[[     0,1,2,3,4,5,6,7,8,9,10]], axis=1, )\n",
    "\n",
    "print(res.columns)\n",
    "res.columns = df_train_B.columns\n",
    "\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "cv_params = {'n_estimators':[100] }\n",
    "other_params = {    \n",
    "                   # step1: 24\n",
    "                    \"n_estimators\":100\n",
    "                  # step2: 4, 3\n",
    "                    , \"max_depth\":4\n",
    "                    , \"min_child_weight\" : 3\n",
    "\n",
    "                  # step3:\n",
    "                    , \"subsample\" : 0.9\n",
    "                    , \"colsample_bytree\" : 0.4\n",
    "\n",
    "\n",
    "                    , \"learning_rate\":0.1\n",
    "\n",
    "                    , \"verbosity\":1\n",
    "                    , \"silent\":None\n",
    "                    , \"objective\":'binary:logistic'\n",
    "                    , \"booster\": \"gbtree\"\n",
    "                    , \"n_jobs\" : 1\n",
    "                    , \"nthread\" : None\n",
    "                    , \"gamma\" : 0.3\n",
    "\n",
    "                    , \"max_delta_step\" : 0\n",
    "\n",
    "                    , \"colsample_bylevel\" : 1\n",
    "                    , \"colsample_bynode\" : 1\n",
    "                    , \"reg_alpha\" : 0\n",
    "                    , \"reg_lambda\" : 1\n",
    "                    , \"scale_pos_weight\" : 1\n",
    "                    , \"base_score\" : 0.5\n",
    "                    , \"random_state\" : 42\n",
    "                    , \"seed\"  : None\n",
    "                    , \"missing\" : None\n",
    "                    , \"importance_type\" :'gain'\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(**other_params)\n",
    "optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='accuracy', cv=5, verbose=1, n_jobs=4)\n",
    "optimized_GBM.fit(df_train_B, df_target)\n",
    "\n",
    "\n",
    "evalute_result = optimized_GBM.cv_results_['mean_test_score']\n",
    "print('每轮迭代运行结果:{0}'.format(evalute_result))\n",
    "print('参数的最佳取值：{0}'.format(optimized_GBM.best_params_))\n",
    "print('最佳模型得分:{0}'.format(optimized_GBM.best_score_))\n",
    "clf_2 = optimized_GBM.best_estimator_\n",
    "\n",
    "pre = clf_2.predict(res)\n",
    "res[\"Label\"] = pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute4</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5973</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5982</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5987</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5988</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5990</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attribute4  Attribute5  Attribute6  Attribute7  Attribute8  Attribute9  \\\n",
       "0              1           2           2           1           2           1   \n",
       "1              2           2           2           1           2           4   \n",
       "2              2           2           2           1           2           4   \n",
       "3              2           2           2           1           3           4   \n",
       "4              2           2           2           1           3           4   \n",
       "5              2           2           2           1           3           4   \n",
       "6              2           2           2           1           3           4   \n",
       "7              2           2           2           1           3           4   \n",
       "8              2           2           2           1           3           4   \n",
       "9              2           2           2           1           3           4   \n",
       "10             2           2           2           1           3           4   \n",
       "11             1           2           2           1           2           1   \n",
       "12             1           2           2           1           2           3   \n",
       "13             1           2           2           1           2           3   \n",
       "14             1           2           2           1           2           3   \n",
       "15             1           2           2           1           2           3   \n",
       "16             1           2           2           1           2           3   \n",
       "17             1           2           2           1           2           3   \n",
       "18             1           2           2           1           2           3   \n",
       "19             1           2           2           1           2           3   \n",
       "20             2           2           2           1           3           1   \n",
       "21             1           2           2           1           2           3   \n",
       "22             1           2           2           1           2           3   \n",
       "23             1           2           2           1           2           3   \n",
       "24             1           2           2           1           2           3   \n",
       "25             1           2           2           1           2           1   \n",
       "26             1           2           2           1           2           1   \n",
       "27             1           2           2           1           2           1   \n",
       "28             1           2           2           1           2           1   \n",
       "29             1           2           2           1           2           1   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "5970           1           2           2           1           2           1   \n",
       "5971           1           2           2           1           2           3   \n",
       "5972           1           2           2           1           2           3   \n",
       "5973           2           2           2           1           3           1   \n",
       "5974           1           2           2           1           2           1   \n",
       "5975           1           2           2           1           2           1   \n",
       "5976           1           2           2           1           2           1   \n",
       "5977           1           1           2           1           2           1   \n",
       "5978           2           2           2           1           2           3   \n",
       "5979           1           2           2           1           2           3   \n",
       "5980           2           2           2           1           3           1   \n",
       "5981           1           1           2           1           2           1   \n",
       "5982           1           2           2           1           3           1   \n",
       "5983           2           2           2           1           3           1   \n",
       "5984           1           2           2           1           2           3   \n",
       "5985           1           2           2           1           2           1   \n",
       "5986           1           1           2           1           2           1   \n",
       "5987           1           1           2           1           2           1   \n",
       "5988           1           2           2           1           3           4   \n",
       "5989           1           2           2           1           2           1   \n",
       "5990           1           2           2           1           2           3   \n",
       "5991           1           2           2           1           2           1   \n",
       "5992           1           2           2           1           2           1   \n",
       "5993           1           2           2           1           2           1   \n",
       "5994           1           2           2           1           2           1   \n",
       "5995           1           2           2           1           2           3   \n",
       "5996           1           2           2           1           2           1   \n",
       "5997           1           2           2           1           2           1   \n",
       "5998           1           2           2           1           3           1   \n",
       "5999           1           2           2           1           2           1   \n",
       "\n",
       "      Attribute10  Label  \n",
       "0               2      3  \n",
       "1               2      0  \n",
       "2               3      0  \n",
       "3               2      0  \n",
       "4               2      0  \n",
       "5               2      0  \n",
       "6               2      0  \n",
       "7               2      0  \n",
       "8               2      0  \n",
       "9               2      0  \n",
       "10              2      0  \n",
       "11              2      3  \n",
       "12              2      1  \n",
       "13              2      1  \n",
       "14              2      1  \n",
       "15              2      1  \n",
       "16              2      1  \n",
       "17              2      1  \n",
       "18              2      1  \n",
       "19              2      1  \n",
       "20              3      2  \n",
       "21              2      1  \n",
       "22              2      1  \n",
       "23              2      1  \n",
       "24              2      1  \n",
       "25              2      3  \n",
       "26              2      3  \n",
       "27              2      3  \n",
       "28              2      3  \n",
       "29              1      2  \n",
       "...           ...    ...  \n",
       "5970            2      3  \n",
       "5971            2      1  \n",
       "5972            2      1  \n",
       "5973            2      2  \n",
       "5974            1      2  \n",
       "5975            2      3  \n",
       "5976            2      3  \n",
       "5977            1      1  \n",
       "5978            2      1  \n",
       "5979            2      1  \n",
       "5980            2      2  \n",
       "5981            1      1  \n",
       "5982            2      3  \n",
       "5983            2      2  \n",
       "5984            2      1  \n",
       "5985            2      3  \n",
       "5986            1      1  \n",
       "5987            1      1  \n",
       "5988            2      0  \n",
       "5989            2      3  \n",
       "5990            2      1  \n",
       "5991            2      3  \n",
       "5992            2      3  \n",
       "5993            2      3  \n",
       "5994            2      3  \n",
       "5995            2      1  \n",
       "5996            2      3  \n",
       "5997            2      3  \n",
       "5998            2      3  \n",
       "5999            2      3  \n",
       "\n",
       "[6000 rows x 8 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Excellent ratio</th>\n",
       "      <th>Good ratio</th>\n",
       "      <th>Pass ratio</th>\n",
       "      <th>Fail ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.162473</td>\n",
       "      <td>0.303299</td>\n",
       "      <td>0.191523</td>\n",
       "      <td>0.342705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053107</td>\n",
       "      <td>0.344220</td>\n",
       "      <td>0.197447</td>\n",
       "      <td>0.405225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024836</td>\n",
       "      <td>0.243569</td>\n",
       "      <td>0.181621</td>\n",
       "      <td>0.549974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.336851</td>\n",
       "      <td>0.173143</td>\n",
       "      <td>0.464365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081626</td>\n",
       "      <td>0.259660</td>\n",
       "      <td>0.273126</td>\n",
       "      <td>0.385588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Excellent ratio  Good ratio  Pass ratio  Fail ratio\n",
       "Group                                                     \n",
       "0             0.162473    0.303299    0.191523    0.342705\n",
       "1             0.053107    0.344220    0.197447    0.405225\n",
       "2             0.024836    0.243569    0.181621    0.549974\n",
       "3             0.025641    0.336851    0.173143    0.464365\n",
       "4             0.081626    0.259660    0.273126    0.385588"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "testpredict = clf_2.predict_proba(res.iloc[:,:-1])\n",
    "y_pred = pd.DataFrame(\n",
    "    testpredict, columns=[\"Excellent ratio\", \"Good ratio\", \"Pass ratio\", \"Fail ratio\"]\n",
    ")\n",
    "y_pred[\"Group\"] = df_test[\"Group\"]\n",
    "\n",
    "group_pred = y_pred.groupby(\"Group\").mean()\n",
    "for c in [\"Excellent ratio\", \"Good ratio\", \"Pass ratio\", \"Fail ratio\"]:\n",
    "    group_pred[c] /= group_pred.sum(axis=1)\n",
    "    \n",
    "\n",
    "group_pred.to_csv('./result1.csv', index=True, header=True)\n",
    "group_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 类别结果加到原始的测试集\n",
    "df_test = pd.concat([df_test, pd.DataFrame(data=res[\"Label\"])], axis=1,)\n",
    "submit_csv = pd.read_csv(\"submit_example.csv\")\n",
    "submit_csv.head()\n",
    "# 分组计算 概率\n",
    "g = df_test.groupby(\"Group\")\n",
    "group_list = df_test.Group.unique()\n",
    "\n",
    "for i in group_list:\n",
    "    tmp = g.get_group(i)\n",
    "    Excellent = len(tmp[tmp[\"Label\"]==3])/50.0\n",
    "    Good = len(tmp[tmp[\"Label\"]==2])/50.0\n",
    "    Pass = len(tmp[tmp[\"Label\"]==1])/50.0\n",
    "    Fail = len(tmp[tmp[\"Label\"]==0])/50.0\n",
    "    submit_csv[submit_csv[\"Group\"]==i] = [i, Excellent, Good, Pass, Fail]\n",
    "\n",
    "submit_csv.to_csv('./result3.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
